{
 "metadata": {
  "name": "",
  "signature": "sha256:db76353f6126e6c66eaafd679e47cfba1fa56081d9f86bf15c53387ded742eec"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Red convolucional"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vamos a crear una clase que defina una capa de convoluci\u00f3n. Esta capa formar\u00e1 parte de una red LeNet como se puede ver en la figura:\n",
      "\n",
      "<img src=\"http://deeplearning.net/tutorial/_images/mylenet.png\"></img>\n",
      "\n",
      "Como se aprecia en la figura, una capa de convoluci\u00f3n va a estar formada por:\n",
      "\n",
      "<ul>\n",
      "<li>Una convoluci\u00f3n 2D</li>\n",
      "<li>Un max-pooling</li>\n",
      "</ul>\n",
      "\n",
      "Vamos primero a importar las librer\u00edas que necesitamos (entre ellas est\u00e1n las clases CapaOculta y LogisticRegression que hemos hecho en los anteriores Notebooks):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "import scipy.io as io\n",
      "import numpy\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "from theano.tensor.signal import downsample #necesaria para el max-pooling\n",
      "from theano.tensor.nnet import conv # Funci\u00f3n convoluci\u00f3n obtenida de la librer\u00eda nnet de Theano\n",
      "\n",
      "from mlp import CapaOculta, LogisticRegression # Nuestras capas ya definidas de anteriores ejemplos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Clase LeNetConvPoolLayer"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Max-pooling"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Theano dispone de un paquete para realizar el max-pooling, <strong>theano.tensor.signal.downsample.max_pool_2d</strong>. \n",
      "\n",
      "Como entrada a la funci\u00f3n, le debemos incluir:\n",
      "\n",
      "<ul>\n",
      "<li>Un tensor N-dimensional (N >= 2)</li>\n",
      "<li>Y un factor de downscaling</li>\n",
      "</ul>\n",
      "\n",
      "Por ejemplo:\n",
      "(Ver la diferencia entre ambas salidas)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from theano.tensor.signal import downsample\n",
      "\n",
      "input = T.dtensor4('input')\n",
      "maxpool_shape = (2, 2)\n",
      "pool_out = downsample.max_pool_2d(input, maxpool_shape, ignore_border=True)\n",
      "f = theano.function([input],pool_out)\n",
      "\n",
      "invals = numpy.random.RandomState(1).rand(3, 2, 5, 5)\n",
      "print invals.shape\n",
      "print 'Con ignore_border puesto a True:'\n",
      "print 'invals[0, 0, :, :] =\\n', invals[0, 0, :, :]\n",
      "print 'output[0, 0, :, :] =\\n', f(invals)[0, 0, :, :]\n",
      "\n",
      "pool_out = downsample.max_pool_2d(input, maxpool_shape, ignore_border=False)\n",
      "f = theano.function([input],pool_out)\n",
      "print 'Con ignore_border puesto False:'\n",
      "print 'invals[1, 0, :, :] =\\n ', invals[1, 0, :, :]\n",
      "print 'output[1, 0, :, :] =\\n ', f(invals)[1, 0, :, :]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En el ejemplo anterior se ha creado un Tensor de 4 dimensiones. Estas dimensiones podr\u00edan ser en un ejemplo pr\u00e1ctico:\n",
      "\n",
      "<ul>\n",
      "<li>N\u00famero de im\u00e1genes</li>\n",
      "<li>N\u00famero de canales (RGB o gris)</li>\n",
      "<li>Altura</li>\n",
      "<li>Anchura</li>\n",
      "</ul>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Convoluci\u00f3n 2D"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En este caso, Theano dispone de la funci\u00f3n <strong>theano.tensor.signal.conv2d</strong>.\n",
      "\n",
      "Esta funci\u00f3n dispone de dos entradas:\n",
      "\n",
      "<ul>\n",
      "<li> Un tensor 4D para las entradas: [mini-batch size, number of input feature maps, image height, image width]</li>\n",
      "<li> Un tensor 4D para los pesos: [number of feature maps at layer m, number of feature maps at layer m-1, filter height, filter width]</li>\n",
      "<ul>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano\n",
      "from theano import tensor as T\n",
      "from theano.tensor.nnet import conv\n",
      "\n",
      "import numpy\n",
      "\n",
      "rng = numpy.random.RandomState(23455)\n",
      "\n",
      "# instantiate 4D tensor for input\n",
      "input = T.tensor4(name='input')\n",
      "\n",
      "# initialize shared variable for weights.\n",
      "w_shp = (2, 3, 9, 9)\n",
      "w_bound = numpy.sqrt(3 * 9 * 9)\n",
      "W = theano.shared( numpy.asarray(\n",
      "            rng.uniform(\n",
      "                low=-1.0 / w_bound,\n",
      "                high=1.0 / w_bound,\n",
      "                size=w_shp),\n",
      "            dtype=input.dtype), name ='W')\n",
      "\n",
      "# initialize shared variable for bias (1D tensor) with random values\n",
      "b_shp = (2,)\n",
      "b = theano.shared(numpy.asarray(\n",
      "            rng.uniform(low=-.5, high=.5, size=b_shp),\n",
      "            dtype=input.dtype), name ='b')\n",
      "\n",
      "# build symbolic expression that computes the convolution of input with filters in w\n",
      "conv_out = conv.conv2d(input, W)\n",
      "\n",
      "# build symbolic expression to add bias and apply activation function, i.e. \n",
      "#produce neural net layer output\n",
      "output = T.nnet.sigmoid(conv_out + b.dimshuffle('x', 0, 'x', 'x'))\n",
      "\n",
      "# create theano function to compute filtered images\n",
      "f = theano.function([input], output)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "import pylab\n",
      "from PIL import Image\n",
      "\n",
      "# open random image of dimensions 221x221\n",
      "img = Image.open(open('images/teacher.jpg'))\n",
      "# dimensions are (height, width, channel)\n",
      "img = numpy.asarray(img, dtype='float32') / 256.\n",
      "\n",
      "# put image in 4D tensor of shape (1, 3, height, width)\n",
      "img_ = img.transpose(2, 0, 1).reshape(1, 3, 221, 221)\n",
      "filtered_img = f(img_)\n",
      "\n",
      "# plot original image and first and second components of output\n",
      "pylab.subplot(1, 3, 1); pylab.axis('off'); pylab.imshow(img)\n",
      "pylab.gray();\n",
      "# recall that the convOp output (filtered image) is actually a \"minibatch\",\n",
      "# of size 1 here, so we take index 0 in the first dimension:\n",
      "pylab.subplot(1, 3, 2); pylab.axis('off'); pylab.imshow(filtered_img[0, 0, :, :])\n",
      "pylab.subplot(1, 3, 3); pylab.axis('off'); pylab.imshow(filtered_img[0, 1, :, :])\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Todo junto"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LeNetConvPoolLayer(object):\n",
      "    \"\"\"Pool Layer of a convolutional network \"\"\"\n",
      "\n",
      "    def __init__(self, rng, input, filter_shape, image_shape, poolsize=(2, 2)):\n",
      "        \"\"\"\n",
      "        Allocate a LeNetConvPoolLayer with shared variable internal parameters.\n",
      "\n",
      "        :type rng: numpy.random.RandomState\n",
      "        :param rng: a random number generator used to initialize weights\n",
      "\n",
      "        :type input: theano.tensor.dtensor4\n",
      "        :param input: symbolic image tensor, of shape image_shape\n",
      "\n",
      "        :type filter_shape: tuple or list of length 4\n",
      "        :param filter_shape: (number of filters, num input feature maps,\n",
      "                              filter height, filter width)\n",
      "\n",
      "        :type image_shape: tuple or list of length 4\n",
      "        :param image_shape: (batch size, num input feature maps,\n",
      "                             image height, image width)\n",
      "\n",
      "        :type poolsize: tuple or list of length 2\n",
      "        :param poolsize: the downsampling (pooling) factor (#rows, #cols)\n",
      "        \"\"\"\n",
      "\n",
      "        assert image_shape[1] == filter_shape[1]\n",
      "        self.input = input\n",
      "\n",
      "        # there are \"num input feature maps * filter height * filter width\"\n",
      "        # inputs to each hidden unit\n",
      "        fan_in = numpy.prod(filter_shape[1:])\n",
      "        # each unit in the lower layer receives a gradient from:\n",
      "        # \"num output feature maps * filter height * filter width\" /\n",
      "        #   pooling size\n",
      "        fan_out = (filter_shape[0] * numpy.prod(filter_shape[2:]) /\n",
      "                   numpy.prod(poolsize))\n",
      "        # initialize weights with random weights\n",
      "        W_bound = numpy.sqrt(6. / (fan_in + fan_out))\n",
      "        self.W = theano.shared(\n",
      "            numpy.asarray(\n",
      "                rng.uniform(low=-W_bound, high=W_bound, size=filter_shape),\n",
      "                dtype=theano.config.floatX\n",
      "            ),\n",
      "            borrow=True\n",
      "        )\n",
      "\n",
      "        # the bias is a 1D tensor -- one bias per output feature map\n",
      "        b_values = numpy.zeros((filter_shape[0],), dtype=theano.config.floatX)\n",
      "        self.b = theano.shared(value=b_values, borrow=True)\n",
      "\n",
      "        # convolve input feature maps with filters\n",
      "        conv_out = conv.conv2d(\n",
      "            input=input,\n",
      "            filters=self.W,\n",
      "            filter_shape=filter_shape,\n",
      "            image_shape=image_shape\n",
      "        )\n",
      "\n",
      "        # downsample each feature map individually, using maxpooling\n",
      "        pooled_out = downsample.max_pool_2d(\n",
      "            input=conv_out,\n",
      "            ds=poolsize,\n",
      "            ignore_border=True\n",
      "        )\n",
      "\n",
      "        # add the bias term. Since the bias is a vector (1D array), we first\n",
      "        # reshape it to a tensor of shape (1, n_filters, 1, 1). Each bias will\n",
      "        # thus be broadcasted across mini-batches and feature map\n",
      "        # width & height\n",
      "        self.output = T.tanh(pooled_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
      "\n",
      "        # store parameters of this layer\n",
      "        self.params = [self.W, self.b]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "\u00bfC\u00f3mo inclu\u00edmos esta capa/clase en una red?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "B\u00e1sicamente, igual que lo hac\u00edamos para el caso del MLP"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Par\u00e1metros"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "learning_rate = 0.1\n",
      "n_epochs = 500\n",
      "dataset = 'digits.mat'\n",
      "nkerns = [10, 20]\n",
      "batch_size = 5000\n",
      "\n",
      "rng = numpy.random.RandomState(23455)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Cargamos los datos y definimos el n\u00famero de lotes a entrenar en funci\u00f3n del tama\u00f1o del lote"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Cargamos los datos\n",
      "print '... cargando datos'\n",
      "data = io.loadmat(dataset, squeeze_me=True)\n",
      "dataIn = data['X']\n",
      "dataOut = data['y']\n",
      "\n",
      "for i in range(len(dataOut)):\n",
      "    if (dataOut[i] == 10):\n",
      "        dataOut[i] = 0\n",
      "\n",
      "train_set_x = theano.shared(numpy.asarray(dataIn, dtype=theano.config.floatX),\n",
      "                            borrow=True)\n",
      "train_set_y = T.cast(theano.shared(numpy.asarray(dataOut,\n",
      "    dtype=theano.config.floatX), borrow=True), 'int32')\n",
      "\n",
      "n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Definimos los tensores"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = T.iscalar()  # \u00cdndice al lote a procesar\n",
      "x = T.matrix('x')   # Las im\u00e1genes de entrada\n",
      "y = T.ivector('y')  # Las etiquetas correspondientes a los n\u00fameros [1..10], correspondiendo el 10\n",
      "# con el \"0\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Construimos el modelo"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '... building the model'\n",
      "\n",
      "layer0_input = x.reshape((batch_size, 1, 20, 20))\n",
      "\n",
      "layer0 = LeNetConvPoolLayer(\n",
      "    rng,\n",
      "    input=layer0_input,\n",
      "    image_shape=(batch_size, 1, 20, 20),\n",
      "    filter_shape=(nkerns[0], 1, 5, 5),\n",
      "    poolsize=(1, 1)\n",
      ")\n",
      "\n",
      "layer1 = LeNetConvPoolLayer(\n",
      "    rng,\n",
      "    input=layer0.output,\n",
      "    image_shape=(batch_size, nkerns[0], 16, 16),\n",
      "    filter_shape=(nkerns[1], nkerns[0], 3, 3),\n",
      "    poolsize=(1, 1)\n",
      ")\n",
      "\n",
      "layer2_input = layer1.output.flatten(2)\n",
      "\n",
      "layer2 = CapaOculta(\n",
      "    rng,\n",
      "    input=layer2_input,\n",
      "    n_in=nkerns[1] * 14 * 14,\n",
      "    n_out=500,\n",
      "    activation=T.tanh\n",
      ")\n",
      "\n",
      "layer3 = LogisticRegression(input=layer2.output, n_in=500, n_out=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Creamos la funci\u00f3n Theano de entrenamiento"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cost = layer3.negative_log_likelihood(y)\n",
      "\n",
      "params = layer3.params + layer2.params + layer1.params + layer0.params\n",
      "\n",
      "grads = T.grad(cost, params)\n",
      "\n",
      "updates = [\n",
      "    (param_i, param_i - learning_rate * grad_i)\n",
      "    for param_i, grad_i in zip(params, grads)\n",
      "]\n",
      "\n",
      "train_model = theano.function(\n",
      "    [index],\n",
      "    cost,\n",
      "    updates=updates,\n",
      "    givens={\n",
      "        x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
      "        y: train_set_y[index * batch_size: (index + 1) * batch_size]\n",
      "    }\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Entrenamiento"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '... training'\n",
      "start_time = time.clock()\n",
      "\n",
      "epoch = 0\n",
      "done_looping = False\n",
      "\n",
      "while (epoch < n_epochs) and (not done_looping):\n",
      "    epoch = epoch + 1\n",
      "    if (epoch % 100 == 0):\n",
      "        print \"Epoca: \", repr(epoch)\n",
      "    for minibatch_index in xrange(n_train_batches):\n",
      "\n",
      "        iter = (epoch - 1) * n_train_batches + minibatch_index\n",
      "\n",
      "        if iter % 100 == 0:\n",
      "            print 'training @ iter = ', iter\n",
      "        cost_ij = train_model(minibatch_index)\n",
      "\n",
      "end_time = time.clock()\n",
      "\n",
      "print \"Tiempo de ejecucion es de %.2fm\" % ((end_time-start_time) / 60.)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Predicci\u00f3n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict = theano.function(\n",
      "    inputs=[index],\n",
      "    outputs=layer3.y_pred,\n",
      "    givens={\n",
      "        x: train_set_x[index * batch_size: (index + 1) * batch_size]\n",
      "    }\n",
      ")\n",
      "\n",
      "test = [predict(i) for i\n",
      "        in xrange(n_train_batches)]\n",
      "\n",
      "real = [dataOut for i\n",
      "        in xrange(n_train_batches)]\n",
      "print test\n",
      "print real"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "comparacion= map(lambda x,y:x==y, test, real)\n",
      "count=0\n",
      "for i in range(comparacion[0].shape[0]):\n",
      "    if (comparacion[0][i] == True):\n",
      "        count += 1\n",
      "        \n",
      "print repr(100.*count/5000.) + \"%\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Analizamos los resultados"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Los pesos"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layer0.W.get_value().shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layer1.W.get_value().shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pylab\n",
      "img = numpy.asarray(layer1.W.get_value()[0,0,:,:])\n",
      "pylab.imshow(img)\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Consultamos las salidas de la primera capa"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict = theano.function(\n",
      "    inputs=[index],\n",
      "    outputs=layer0.output,\n",
      "    givens={\n",
      "        x: train_set_x[index * batch_size: (index + 1) * batch_size]\n",
      "    }\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = numpy.asarray(predict(0)[0,0,:,:])\n",
      "pylab.imshow(img)\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataIn.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img=dataIn[1,:].reshape(20,20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab.imshow(img)\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(dataOut)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(dataOut)):\n",
      "    if (dataOut[i] == 10):\n",
      "        dataOut[i] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataOut[20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}