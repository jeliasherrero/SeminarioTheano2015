{
 "metadata": {
  "name": "",
  "signature": "sha256:01fb4284221f299ebd1a9c9b46bd5ef4969472ffff8eb9271921664679ab55a5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Optimizaci\u00f3n para procesamiento GPU"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A continuaci\u00f3n se va a modificar el ejemplo anterior (Logistic Regression) para optimizar su rendimiento cuando se emplea una GPU.\n",
      "\n",
      "El procedimiento es el siguiente:\n",
      "\n",
      "<ul>\n",
      "<li> Analizamos los cambios propuestos.</li>\n",
      "<li> Guardamos el script en lr2.py</li>\n",
      "<li> En la consola escribimos: time THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python lr2.py</li>\n",
      "<li> Y compararlo con: time THEANO_FLAGS=mode=FAST_RUN,device=cpu,floatX=float32 python lr2.py</li>\n",
      "<li> Repetir el paso 3 y 4 para N=4000</li>\n",
      "<ul>\n",
      "\n",
      "Hay que fijarse que estamos testeando el algoritmo con una secuencia aleatoria con una dimensionalidad de 784. No importan los resultados, lo que nos importa en este caso es analizar el tiempo de ejecuci\u00f3n."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "from theano import sandbox, Out\n",
      "\n",
      "theano.config.floatX='float32'\n",
      "\n",
      "rng = numpy.random\n",
      "\n",
      "import scipy.io as io\n",
      "        \n",
      "print '... cargando datos'\n",
      "'''data=io.loadmat('dataLR.mat',squeeze_me=True)\n",
      "dataIn=data['data'][:,0:2].astype(theano.config.floatX)\n",
      "dataOut = data['data'][:,2].astype(theano.config.floatX)'''\n",
      "training_steps = 10000\n",
      "\n",
      "N = 400\n",
      "feats = 784\n",
      "D = (rng.randn(N, feats).astype(theano.config.floatX),\n",
      "rng.randint(size=N, low=0, high=2).astype(theano.config.floatX))\n",
      "dataIn=D[0]\n",
      "dataOut=D[1]\n",
      "\n",
      "# Declare Theano symbolic variables\n",
      "x = theano.shared(dataIn, name=\"x\")\n",
      "y = theano.shared(dataOut, name=\"y\")\n",
      "w = theano.shared(rng.randn(dataIn.shape[1]).astype(theano.config.floatX), name=\"w\")\n",
      "b = theano.shared(numpy.asarray(0., dtype=theano.config.floatX), name=\"b\")\n",
      "x.tag.test_value = dataIn\n",
      "y.tag.test_value = dataOut\n",
      "#print \"Initial model:\"\n",
      "#print w.get_value(), b.get_value()\n",
      "\n",
      "# Construct Theano expression graph\n",
      "p_1 = 1 / (1 + T.exp(-T.dot(x, w)-b)) # Probability of having a one\n",
      "prediction = p_1 > 0.5 # The prediction that is done: 0 or 1\n",
      "xent = -y*T.log(p_1) - (1-y)*T.log(1-p_1) # Cross-entropy\n",
      "cost = xent.mean() + 0.01*(w**2).sum() # The cost to optimize\n",
      "gw,gb = T.grad(cost, [w,b])\n",
      "\n",
      "# Compile expressions to functions\n",
      "train = theano.function(\n",
      "            inputs=[],\n",
      "            outputs=[prediction, xent],\n",
      "            updates={w:w-0.01*gw, b:b-0.01*gb},\n",
      "            name = \"train\",allow_input_downcast=True)\n",
      "predict = theano.function(inputs=[], outputs=prediction,\n",
      "            name = \"predict\",allow_input_downcast=True)\n",
      "\n",
      "if any([x.op.__class__.__name__ in ['Gemv', 'CGemv', 'Gemm', 'CGemm'] for x in\n",
      "        train.maker.fgraph.toposort()]):\n",
      "    print 'Used the cpu'\n",
      "elif any([x.op.__class__.__name__ in ['GpuGemm', 'GpuGemv'] for x in\n",
      "          train.maker.fgraph.toposort()]):\n",
      "    print 'Used the gpu'\n",
      "else:\n",
      "    print 'ERROR, not able to tell if theano used the cpu or the gpu'\n",
      "    print train.maker.fgraph.toposort()\n",
      "\n",
      "for i in range(training_steps):\n",
      "    pred, err = train()\n",
      "#print \"Final model:\"\n",
      "#print w.get_value(), b.get_value()\n",
      "\n",
      "print \"target values for D\"\n",
      "print dataOut\n",
      "\n",
      "print \"prediction on D\"\n",
      "print predict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}